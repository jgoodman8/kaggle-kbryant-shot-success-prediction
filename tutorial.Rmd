---
title: "Kaggle Competition: Kobe Bryant Shot Selection"
author: "Javier Guzmán Figueira Domínguez"
date: "12/03/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/cento/Documents/MasterUIMP/Practicas/supervisados/kobe-bryant-shot-selection")
```

# Introducción

En este documento se tratará el problema presentado la competición de [Kaggle](https://www.kaggle.com/) bajo el título [Kobe Bryant Shot Selection](https://www.kaggle.com/c/kobe-bryant-shot-selection). El objetivo de esta competición es la de realizar una clasificación de tiros encestados y fallados por Kobe Bryant.

La competición proporciona un dataset con 30.697 instancias y 25 variables, incluída la variable clase. Esta variable clase está definida de forma binaria, tomando valor 1 en caso de tratarse de un tiro acertado y 0 en caso de un tiro fallido.

El conjunto de test está representado por un subconjunto de 5.000 intancias con ausencia de la etiqueta de clase. Para estas instancias, se deberá de predecir la probabilidad que cada tiro se enceste. El *score* utilizado por *Kaggle* en esta competición es la pérdida logarítica o *log loss*.

```{r}
library(caret)
library(ggplot2)
library(kernlab)

data <- read.csv("data.csv")

dim(data)
```

# Análisis de la variables

En esta sección, se realizará una describición y análisis de cada una de las variables predictoras del dataset y la variable clase. A continuación, se muestra el listado de variables con algunas de sus características internas.

```{r}
str(data)
```

## Variable clase: *shot_made_flag*

Tal y como se ha comentado, existen 5.000 instancias sin los valores de la variable clase. Estas serán las instancias para las que debamos realizar nuestra predicción.

```{r}
print("Número de instancias totales con valores perdidos")
sum(is.na(data$shot_made_flag))

print("Número de instancias totales con valores perdidos, no teniendo en cuenta 'shot_made_flag'")
sum(is.na(dplyr::select(data, - shot_made_flag)))
```

Por consiguiente, realizaremos una separación de ambos subconjuntos y los denominaremos conjuntos de entrenamiento o *train* y de prueba o *test*. Es obvio que el conjunto de test contedrá las 5.000 instancias con ausencia de etiqueta para *shot_made_flag*. Por otra parte, el conjunto de entrenamiento ahora constará de un total de 25.697 instancias.

```{r}
train <- data[!is.na(data$shot_made_flag),]
test <- data[is.na(data$shot_made_flag),]

train$shot_made_flag <- as.factor(train$shot_made_flag)
test <- dplyr::select(test, - shot_made_flag)

dim(train)

dim(test)
```

Antes de analizar las variables predictoras, observamos la distribución de la variables clase y advertimos que las categorías están bastante parejas, al menos en el conjunto de entrenamiento. De esta forma, un 55,39% de los tiros han sido fallidos y el restante 44,62% consta de tiros encestados, tal y como muestra la gráfica.

```{r}
shot_made_flag.misses <- format(round((length(train$shot_made_flag[train$shot_made_flag == 0])/nrow(train)) * 100,  2), nsmall = 2)
shot_made_flag.swishes <- format(round((length(train$shot_made_flag[train$shot_made_flag == 1])/nrow(train)) * 100,  2), nsmall = 2)
shot_made_flag.names <- c(paste("Misses - ", shot_made_flag.misses, "%"), paste("Swishes - ", shot_made_flag.swishes, "%"))

barplot(table(train$shot_made_flag), names = shot_made_flag.names)
```

## Clasificación del tiro según la forma

La variable *action_type* referencia el tipo de acción mediante el que se realizó/intentó la canasta. Se definen hasta 57 tipos diferentes de acciones, siendo *Jump Shot* la más frecuente. A continuación, se muestran dichos tipos:

```{r}
levels(data$action_type)
```

A continuación, se muestra la relación entre la preción en el tiro según el tipo de acción realizada. Dado que la variable *action_type* contiene multitud de categorías, se han seleccionado aquellas que representan más de 20 lanzamientos. Las restantes se han juntado en una nueva categoría, bajo el nombre de *Others*.

```{r}
action_type <- train$action_type
action_type.is.frequent <- sapply(levels(action_type), function(level){ length(action_type[action_type == level]) > 20 })
action_type.frequent.levels <- subset(levels(action_type), action_type.is.frequent)

action_type <- as.character(action_type)
action_type[!action_type %in% action_type.frequent.levels] <- "Other"
action_type <- as.factor(action_type)
```

A continuación, se define una función para mostrar la proporción de aciertos y errores (en los tiros realizados), en función de una determina característica y ordenados en función de dicha proporción

```{r}
plotOrderedAccuracyByFeature <- function(feature) {

  temp <- prop.table(table(feature, train$shot_made_flag), 1)
  temp <- as.data.frame.matrix(temp)
  temp$shot <- rownames(temp)
  
  ggplot(temp, aes(x = reorder(shot, `1`), y = 1)) +
    geom_point(aes(y = `1`), size = 2, stat = "identity") + 
    coord_flip() + 
    xlab("") +
    ylab("Accuracy")
}
```

Se aprecia como, efectivamente, existe una clara diferencia de probabilidad de acierto según el tipo de acción. Los tipos con mayor *accuracy* son *Slam Dunk Shot*, *Driving Slam Dunk Shot* y *Driving Dunk Shot*, mientras que *Jump Shot*, *Tip Shot*, *Hook Shot* y *Layup Shot* son las acciones con menor probabilidad de acierto.

```{r}
plotOrderedAccuracyByFeature(action_type)
```


Otra variable que describe el tipo de tiro realizado es *combined_shot_type*. Es de tipo categórica y comprende los siguientes tipos:

```{r}
levels(train$combined_shot_type)
```

De la misma forma que se hizo con la variable *action_type*, realizaremos una comparativa entre los tipos de tiros y sus respectivas probabilidades de acierto. De igual manera, existen claras relaciones en dicha comparativa. Observamos una alta probabilidad asociada a mates (*dunks*) y tiros libres (*Bank Shots*).

```{r}
plotOrderedAccuracyByFeature(train$combined_shot_type)
```

Finalmente, la variable *shot_type* también nos aporta valiosa información sobre el tipo de tiro. Esta variable categórica, nos informa de si se trata de un tiro de 2 o 3 puntos.

```{r}
levels(data$shot_type)
```

A continuación, se representa su relación con la precisión en los tiros realizados. Para ello, se define una función, que de forma muy similar a la anterior, nos muestra la la proporción de aciertos y errores (en los tiros realizados), en función de una característica dada.

```{r}
plotAccuracyByFeature <- function(feature, feature.name, x.angle = 0) {
  ggplot(data = train, aes(x = feature)) +  
    geom_bar(aes(fill = shot_made_flag), stat = "count", position = "fill") + 
    xlab(feature.name) + 
    ylab("Accuracy") + 
    theme(axis.text.x = element_text(angle = x.angle, hjust = ifelse(x.angle == 0, .5, 1))) + 
    guides(fill = guide_legend(title = "Shot swished"))
}
```

```{r}
plotAccuracyByFeature(train$shot_type, "Shot type")
```

## Identificadores genéricos

Las propiedades *game_id* y *game_event_id* representan los idenficadores de partido y de evento en cada partido, respectivamente. En princio, no aportan información más allá de ayudarnos a estudiar las acciones agrupadas por partido. 

En cuanto a las variables *team_id* y *team_name*, carencen completamente de interés. Estas recogen, respectivamente, el idenficador de equipo y su nombre. Dado que el dataset contiene datos sobre los tiros realizados en un único equipo, estas características no aportan información útil.

```{r}
unique(data$team_id)

levels(data$team_name)
```

## Variables referentes al partido

La variable *matchup* incluye la información de los equipos que han participado en el partido. Sin embargo, sabemos que el dataset recoge los datos de los tiros realizados por K. Bryant en Los Angeles Lakers y la variable *opponent* contiene el nombre del equipo advesario. La información útil que podemos extraer de *matchup* es saber si una determinada acción se ha realizado como local o visitante.

```{r}
print("Oponentes")
levels(data$opponent)

print("Enfrentamientos")
levels(data$matchup)
```

Así mismo, las variables *season* y *period* referencian la temporada en la que se produjo el tiro y el periodo dentro del partido, respectivamente.

```{r}
print("Temporadas")
levels(data$season)

print("Periodos del partido")
unique(data$period)
```

```{r}
plotAccuracyByFeature(train$season, "Season", 60)
```

```{r}
plotAccuracyByFeature(as.factor(train$period), "Period")
```

Otra variable interesante podría ser *playoffs*, ya que nos informa si un partido dado es de play-off (representado con un 1) o no (0).

```{r}
unique(data$playoffs)
```

```{r}
plotAccuracyByFeature(as.factor(train$playoffs), "Play-off")
```

Así mismo, puede ser relevante estudiar las variables *minutes_remaining* y *seconds_remaining*. Estas propiedades expresa los segundos y minutos restantes en el momento del lanzamiento. Al visualizarlos, no se aprecia que estas características tengan un impacto claro en la probabilidad de acierto/fallo. Se ha podido apreciar que lo mismo ocurre con las otras variables incluídas en esta categoría.

```{r}
plotAccuracyByFeature(as.factor(train$minutes_remaining), "Minutes remaing")
plotAccuracyByFeature(as.factor(train$seconds_remaining), "Seconds remaining", 90)
```

Finalmente, la variable *game_date* representa la fecha en la que se ha producido cada enfrentamiento y, por lo tanto, cada tiro. Así mismo, las variables *lat* y *lon* representan la latitud y logitud en la que se realizaron los tiros.

## Variables referentes a la cancha

En primer lugar, prestamos atención a las variables *loc_x* y *loc_y*. Conjuntamente representan las posición de la cancha de baloncesto en la que se realizó cada lanzamiento. Observamos como, a simple vista, no existe ninguna zona de la cancha con una mayor concentración de canastas o errores.

```{r}
ggplot(train, aes(x = loc_x, y = loc_y)) +
    geom_point(aes(color = shot_made_flag), alpha = 0.5, size = 0.5) +
    ylim(c(-50, 400)) +
    theme_void() +
    facet_grid(~shot_made_flag)
```

La variables *shot_zone_area*, *shot_zone_basic* y *shot_zone_range* representan la cancha dividada por zonas y expresan la zona en la que se produjo la acción. En primer lugar, mostramos las parcelas de la cancha:

```{r}
ggplot(train, aes(x = loc_x, y = loc_y)) +
    geom_point(aes(color = shot_zone_area), alpha = 0.5, size = 0.5) +
    ylim(c(-50, 400)) +
    guides(fill = guide_legend(title = "Shot zone areas"))

ggplot(train, aes(x = loc_x, y = loc_y)) +
    geom_point(aes(color = shot_zone_basic), alpha = 0.5, size = 0.5) +
    ylim(c(-50, 400)) +
    guides(fill = guide_legend(title = "Shot zone basic"))

ggplot(train, aes(x = loc_x, y = loc_y)) +
    geom_point(aes(color = shot_zone_range), alpha = 0.5, size = 0.5) +
    ylim(c(-50, 400)) +
    guides(fill = guide_legend(title = "Shot zone range"))
```

A continuación, se muestra el ratio de acierto en cada una de las zonas de la cancha.

```{r}
plotAccuracyByFeature(as.factor(train$shot_zone_area), "Shot zone area")
plotAccuracyByFeature(as.factor(train$shot_zone_basic), "Shot zone basic")
plotAccuracyByFeature(as.factor(train$shot_zone_range), "Shot zone range")
```

Finalmente, la variable *shot_distance* describe la distancia a la que se ha realizado el tiro, con respecto a la canasta.

```{r}
plotAccuracyByFeature(as.factor(train$shot_distance), "Shot distance")
```

# Transformación de los datos

En primer lugar, eliminamos las variables que, tal y como se ha comentado en la sección anterior, no aportan información relevante.

```{r}
train <- dplyr::select(train, - game_event_id)
train <- dplyr::select(train, - game_id)
train <- dplyr::select(train, - team_id)
train <- dplyr::select(train, - team_name)
train <- dplyr::select(train, - shot_id)
train <- dplyr::select(train, - game_date)
train <- dplyr::select(train, - loc_x)
train <- dplyr::select(train, - loc_y)
train <- dplyr::select(train, - lat)
```

A continuación, utilizamos la variable *matchup* para obtener información más valiosa que el nombre del enfrentamiento. Los enfrentamientos que contienen el símbolo "*@*"" representan enfrentamientos como equipo local. Por consiguiente, los partidos que contienen "*VS*" en el nombre, son partidos jugados como visitante. En función de esto, creamos la variable *visitor* con el fin de clarificar el rol del equipo en el partido. Aún así, no se observa diferencia en la efectividad en relación a jugar un partido como visitante o como local

```{r}
train$visitor <- ifelse(grepl("@", train$matchup), 0, 1)
train$visitor <- as.factor(train$visitor)
train <- dplyr::select(train, - matchup)

plotAccuracyByFeature(as.factor(train$visitor), "Visitor")
```

Existen algunos tipos de métodos analíticos que tienen problemas al tratar variables categóricas. Por lo tanto, se procede a la conversión de dicho tipo de variables a numéricas. Para ello, se asigna a cada categoría un entero, generado de forma incremental en cada característica.

```{r}
for (i in 1:ncol(train)) {
    if (is.factor(train[, i])) {
        levels(train[, i]) <- c(1:length(levels(train[, i])))
        train[, i] <- as.numeric(train[, i])
    }
}
```

En contraste, al tratarse de una tarea de clasificación, necesitamos que nuesta variable clase sea de tipo categórico. En consecuencia, procedemos a asignar el tipo *SUCCESS* a aquellos tiros acertados y *ERROR* a las canastas fallidas.

```{r}
train$shot_made_flag <- as.factor(ifelse(train$shot_made_flag == 1, "SUCCESS", "ERROR"))
```

Dado que el conjunto de test no contiene las etiquetas de la variable clase, no podremos validar nuestro modelo contra el conjunto de test. Aunque si podremos comprobar el *score* que la plataforma *Kaggle* asigna a nuestra predicción. Por lo tanto, particionaremos el conjunto de entrenamiento en dos subconjuntos: uno para el entrenamiento (parcial) del modelo y otro para realizar la validación.

```{r}
inTrain <- caret::createFolds(y = train$shot_made_flag, k = 2, list = TRUE)
train.partition <- train[inTrain$Fold1,]
validation.partition <- train[-inTrain$Fold2,]
```



```{r}
#train.partition.preProcessed <- preProcess(dplyr::select(train.partition, - shot_made_flag), )
#train.partition.preProcessed <- predict(train.partition.preProcessed, train.partition)
```

# Entrenamiento y validación

En primer lugar, utilizamos la función *trainControl* para generar los parámetros que, más tarde, utilizaremos para controlar el entramiento del modelo. De esta forma controlaremos el tipo de estimación del error; en este caso utilizaremos una validación cruzada de 10 hojas o *folds* (por defecto). Dicha validación la repetiremos 3 veces, utilizando el parámetro *repeats = 3* conjuntamente con el parámetro *method = "repeatedcv"*, ya que *method = "cv"* no permite seleccionar repeticiones. Así mismo, nos interesa obtener las probabilidades con las que cada instancia pertenece a cada clase, por lo que utilizamos el parámetro *classProbs = TRUE*.

La evaluación de esta competición se realiza utilizando la métrica *Log Loss*, por lo que será interesante utilizar dicha métrica para seleccionar el modelo óptimo. *Logarithmic loss* mide el rendimiento de un modelo de clasificación en el cual la predicción viene dada por un valor de probabilidad entre 0 y 1. Idealmente, un modelo perfecto prediciría con una *Log Loss* de 0, dado que la métrica se incrementa cuando la probabilidad predicha diverge de la etiqueta real. 

Al no ser una métrica que proporcione por defecto el paquete *caret*, definimos la función *LogLoss* para incluirla por medio del parámetro *summaryFunction*.

```{r}
LogLoss <- function(data, lev = NULL, model = NULL) {
    obs <- data[, "obs"]
    cls <- levels(obs) # find class names
    probs <- data[, cls[2]] # use second class name
    probs <- pmax(pmin(as.numeric(probs), 1 - 1e-15), 1e-15) # bound probability
    logPreds <- log(probs)
    log1Preds <- log(1 - probs)
    real <- (as.numeric(data$obs) - 1)
    out <- c(mean(real * logPreds + (1 - real) * log1Preds)) * -1
    names(out) <- c("LogLoss")
    out
}

control <- caret::trainControl(method = "repeatedcv", repeats = 3, classProbs = TRUE, summaryFunction = LogLoss, verboseIter = TRUE)
```

```{r}
fpa.info <- caret::getModelInfo("S")
fpa.info$fda$parameters
```

```{r}
modelGLM <- caret::train(shot_made_flag ~ ., data = train.partition, method = "glm", trControl = control, 
                         preProc = c("center"), tuneLength = 20, metric = "LogLoss", maximize = FALSE)
plot(modelGLM)
```

A continuación, entrenaremos el modelo utilizando un análisis discriminante flexible (*Flexible Discriminant Analysis*). Este tipo de modelo de clasificación se basa en una combinación de modelos de regresión linear. Utiliza un *scoring* óptimo para transformar la variable de respuesta de forma que los datos sean más fáciles de separar linealmente. Así mismo, utiliza múltiples *splines*  adaptativos para generar la supercicie discriminante.

```{r}
fpa.info <- caret::getModelInfo("fda")
fpa.info$fda$parameters
```

Tal y como podemos observar, *fda* contiene dos parámetros: *degree* y *nprune*. A continuación, se procede a entrenar el modelo con el conjunto de entrenamiento que creamos en la sección anterior. En primer lugar, empleamos el número por defecto de valores por parámetro utilzando un total de 3^2 combinaciones. Así mismo, a través del argumento *tunelength* asignamos 20 con el fin de obtener una mayor amplia variedad de 20^2 combinaciones.

```{r}
modelFDA.default <- caret::train(shot_made_flag ~ ., data = train.partition, method = "fda", trControl = control,
                         preProc = c("center"), metric = "LogLoss", maximize = FALSE)

modelFDA.custom <- caret::train(shot_made_flag ~ ., data = train.partition, method = "fda", trControl = control,
                         preProc = c("center"), tuneLength = 20, metric = "LogLoss", maximize = FALSE)

plot(modelFDA.default)
plot(modelFDA.custom)
```

Ahora se procede a realizar la predicción sobre el subconjunto de validación. 

```{r}
validation.partition.y <- ifelse(validation.partition$shot_made_flag == "SUCCESS", 1, 0)
validation.partition.test <- dplyr::select(validation.partition, - shot_made_flag)

prediction.xgb <- predict(modelGLM, newData = validation.partition.test, type = "prob")
score.fda.validation <- MLmetrics::LogLoss(y_pred = prediction.fda$SUCCESS, y_true = validation.partition.y)
score.fda.validation

prediction.fda <- predict(modelFDA.custom, newData = validation.partition.test, type = "prob")
score.fda.validation <- MLmetrics::LogLoss(y_pred = prediction.fda$SUCCESS, y_true = validation.partition.y)
score.fda.validation
```

Dado que el ambos modelos (*fda* y *X*) han sido entrenados con las mismas hojas (no se ha modificado la semilla), podemos comparar los resultados de la crossvalidación de ambos modelos.

```{r}
resamples.result <- resamples(list(glm = modelGLM, fda = modelFDA.custom))
summary(resamples.result)

xyplot(resamples.result, what = "BlandAltman")

diffs <- diff(resamples.result)
summary(diffs)
```


# Generación del modelo final y predicción

```{r}
model <- caret::train(shot_made_flag ~ ., data = train, method = "glm", trControl = control, 
                         preProc = c("center"), tuneLength = 20, metric = "LogLoss", maximize = FALSE)
model
```

```{r}
test <- dplyr::select(test, - game_event_id)
test <- dplyr::select(test, - game_id)
test <- dplyr::select(test, - team_id)
test <- dplyr::select(test, - team_name)
test <- dplyr::select(test, - shot_id)
test <- dplyr::select(test, - game_date)
test <- dplyr::select(test, - loc_x)
test <- dplyr::select(test, - loc_y)
test <- dplyr::select(test, - lat)
```

```{r}
prediction <- predict(model, newData = test, type = "prob")
prediction.table <- data.frame(shot_id = test$shot_id, shot_made_flag = prediction$SUCCESS)
write.csv(prediction.table, "prediction.csv", row.names = FALSE)
```